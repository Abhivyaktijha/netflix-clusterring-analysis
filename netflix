# Netflix Content Clustering & Trend Analysis
# Project: Content Clustering and Trend Analysis on Netflix Dataset using NLP and Unsupervised Learning

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD, PCA
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.metrics import silhouette_score
from scipy.cluster.hierarchy import dendrogram, linkage

# Set Plot Style
plt.style.use('seaborn-v0_8-darkgrid')

# Load Data
netflix = pd.read_csv("NETFLIX_MOVIES_AND_TV_SHOWS.csv")

# Data Cleaning
def clean_data(df):
    df['director'] = df['director'].fillna('No Director')
    df['cast'] = df['cast'].fillna('No Cast')
    df['country'] = df['country'].fillna('No Country')
    df['rating'] = df['rating'].fillna(method='ffill')
    df['description'] = df['description'].str.replace('[^a-zA-Z]', ' ', regex=True).str.lower()
    return df

netflix = clean_data(netflix)

# Preprocess text and reduce dimensions
def preprocess_descriptions(df):
    tfidf = TfidfVectorizer(stop_words='english', max_features=1000)
    tfidf_matrix = tfidf.fit_transform(df['description'])
    svd = TruncatedSVD(n_components=50, random_state=42)
    reduced = svd.fit_transform(tfidf_matrix)
    return tfidf, tfidf_matrix, reduced

tfidf, tfidf_matrix, tfidf_reduced = preprocess_descriptions(netflix)

# Clustering Function
def perform_clustering(data, method='kmeans', n_clusters=4):
    if method == 'kmeans':
        model = KMeans(n_clusters=n_clusters, random_state=42)
    else:
        model = AgglomerativeClustering(n_clusters=n_clusters)
    labels = model.fit_predict(data)
    return model, labels

kmeans_model, kmeans_labels = perform_clustering(tfidf_reduced, method='kmeans', n_clusters=4)
pca = PCA(n_components=10)
tfidf_pca = pca.fit_transform(tfidf_reduced)
agg_model, agg_labels = perform_clustering(tfidf_pca, method='agglo', n_clusters=4)

netflix['KMeans_Cluster'] = kmeans_labels
netflix['Agglo_Cluster'] = agg_labels

# Evaluate
print("Silhouette Score (KMeans):", silhouette_score(tfidf_reduced, kmeans_labels))
print("Silhouette Score (Agglomerative):", silhouette_score(tfidf_pca, agg_labels))

# Explainability: Top Terms per KMeans Cluster
def get_top_terms(model, feature_names, n_terms=10):
    centers = model.cluster_centers_
    top_terms = []
    for i in range(centers.shape[0]):
        top_indices = centers[i].argsort()[-n_terms:][::-1]
        top_terms.append([feature_names[i] for i in top_indices])
        print(f"Cluster {i}: {', '.join(top_terms[-1])}")
    return top_terms

feature_names = tfidf.get_feature_names_out()
print("\nTop Terms per KMeans Cluster:")
top_terms = get_top_terms(kmeans_model, feature_names)

# Visualize Clusters in 2D
tsvd = TruncatedSVD(n_components=2)
projected = tsvd.fit_transform(tfidf_matrix)
sns.scatterplot(x=projected[:, 0], y=projected[:, 1], hue=kmeans_labels, palette='Set2')
plt.title("KMeans Clusters Visualization")
plt.xlabel("Component 1")
plt.ylabel("Component 2")
plt.tight_layout()
plt.show()

# Strategy Summary
print("\nCluster Content Focus:")
for i, terms in enumerate(top_terms):
    print(f"Cluster {i}: Focused on content related to {', '.join(terms[:3])}")
